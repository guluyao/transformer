Transformer语言建模实验报告
==================================================

训练时间: 2025-11-08 11:06:53
总epoch数: 5
最终训练损失: 3.8811
总耗时: 7.7分钟

训练配置:
- 模型维度: 128
- 批次大小: 32
- 学习率: 0.0003
- 训练轮次: 5
- 序列长度: 64
- 随机种子: 42
- 是否消融位置编码: 否
- 是否消融多头注意力: 否
- 是否消融FFN: 是

详细结果:
Epoch 1: 训练损失=4.3202, 验证损失=4.3182, 困惑度=75.05
Epoch 2: 训练损失=4.2441, 验证损失=4.1991, 困惑度=66.62
Epoch 3: 训练损失=4.1135, 验证损失=4.0565, 困惑度=57.77
Epoch 4: 训练损失=3.9902, 验证损失=3.9404, 困惑度=51.44
Epoch 5: 训练损失=3.8811, 验证损失=3.8376, 困惑度=46.41
