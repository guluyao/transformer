Transformer语言建模实验报告
==================================================

训练时间: 2025-11-08 10:54:48
总epoch数: 5
最终训练损失: 3.6105
总耗时: 9.4分钟

训练配置:
- 模型维度: 128
- 批次大小: 32
- 学习率: 0.0003
- 训练轮次: 5
- 序列长度: 64
- 随机种子: 42
- 是否消融位置编码: 否
- 是否消融多头注意力: 是

详细结果:
Epoch 1: 训练损失=4.3801, 验证损失=4.3213, 困惑度=75.29
Epoch 2: 训练损失=4.2199, 验证损失=4.0856, 困惑度=59.48
Epoch 3: 训练损失=3.9583, 验证损失=3.8390, 困惑度=46.48
Epoch 4: 训练损失=3.7514, 验证损失=3.6734, 困惑度=39.38
Epoch 5: 训练损失=3.6105, 验证损失=3.5614, 困惑度=35.21
